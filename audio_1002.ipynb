{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1lecF6BA6HmytEzbhdICm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anomara1/DrAhmedOmara/blob/main/audio_1002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pesq pystoi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO221Jmo9OM3",
        "outputId": "e6079d12-9127-448f-ed0c-d098293827b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pesq\n",
            "  Downloading pesq-0.0.4.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pystoi\n",
            "  Downloading pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pystoi) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pystoi) (1.13.1)\n",
            "Downloading pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Building wheels for collected packages: pesq\n",
            "  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pesq: filename=pesq-0.0.4-cp311-cp311-linux_x86_64.whl size=275943 sha256=1d68a6792be57d5e558dd126d8e9233a24d37b55de48418193091cbabcd17405\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/f1/23/2698d0bf31eec2b2aa50623b5d93b6206c49c7155d0e31345d\n",
            "Successfully built pesq\n",
            "Installing collected packages: pesq, pystoi\n",
            "Successfully installed pesq-0.0.4 pystoi-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vxZKO1O7Nd5X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.signal\n",
        "import scipy.spatial\n",
        "import scipy.stats\n",
        "from scipy.linalg import norm\n",
        "import pesq  # For PESQ metric\n",
        "from pystoi import stoi  # For STOI metric\n",
        "\n",
        "class SignalMetrics:\n",
        "    def __init__(self, original, processed, sr=16000):\n",
        "        \"\"\"\n",
        "        Initialize with original and processed signals.\n",
        "        :param original: 1D numpy array of the original signal\n",
        "        :param processed: 1D numpy array of the processed signal\n",
        "        :param sr: Sampling rate of the signals (default 16 kHz)\n",
        "        \"\"\"\n",
        "        self.original = original\n",
        "        self.processed = processed\n",
        "        self.sr = sr\n",
        "\n",
        "    def log_spectral_distance(self):\n",
        "        \"\"\"Log Spectral Distance (LSD)\"\"\"\n",
        "        orig_spec = np.abs(librosa.stft(self.original)) + 1e-10\n",
        "        proc_spec = np.abs(librosa.stft(self.processed)) + 1e-10\n",
        "        lsd = np.mean((10 * np.log10(orig_spec / proc_spec)) ** 2)\n",
        "        return np.sqrt(lsd)\n",
        "\n",
        "    def mel_cepstral_distance(self):\n",
        "        \"\"\"Mel-Cepstral Distance (MCD)\"\"\"\n",
        "        orig_mfcc = librosa.feature.mfcc(y=self.original, sr=self.sr)\n",
        "        proc_mfcc = librosa.feature.mfcc(y=self.processed, sr=self.sr)\n",
        "        return np.mean(np.linalg.norm(orig_mfcc - proc_mfcc, axis=0))\n",
        "\n",
        "    def segmental_snr(self, frame_length=2048, overlap=1024):\n",
        "        \"\"\"Segmental Signal-to-Noise Ratio (SegSNR)\"\"\"\n",
        "        orig_frames = librosa.util.frame(self.original, frame_length=frame_length, hop_length=overlap)\n",
        "        proc_frames = librosa.util.frame(self.processed, frame_length=frame_length, hop_length=overlap)\n",
        "\n",
        "        snr_list = []\n",
        "        for o, p in zip(orig_frames.T, proc_frames.T):\n",
        "            noise = o - p\n",
        "            if np.any(o ** 2):\n",
        "                snr_list.append(10 * np.log10(np.mean(o ** 2) / (np.mean(noise ** 2) + 1e-10)))\n",
        "\n",
        "        return np.mean(snr_list) if snr_list else 0  # Avoid empty list issue\n",
        "\n",
        "    def spectral_flatness_measure(self):\n",
        "        \"\"\"Spectral Flatness Measure (SFM)\"\"\"\n",
        "        orig_spec = np.abs(librosa.stft(self.original)) + 1e-10\n",
        "        proc_spec = np.abs(librosa.stft(self.processed)) + 1e-10\n",
        "        orig_sfm = scipy.stats.gmean(orig_spec, axis=0) / np.mean(orig_spec, axis=0)\n",
        "        proc_sfm = scipy.stats.gmean(proc_spec, axis=0) / np.mean(proc_spec, axis=0)\n",
        "        return np.mean(np.abs(orig_sfm - proc_sfm))\n",
        "\n",
        "    def spectral_centroid_distance(self):\n",
        "        \"\"\"Spectral Centroid Distance\"\"\"\n",
        "        orig_centroid = librosa.feature.spectral_centroid(y=self.original, sr=self.sr)\n",
        "        proc_centroid = librosa.feature.spectral_centroid(y=self.processed, sr=self.sr)\n",
        "        return np.mean(np.abs(orig_centroid - proc_centroid))\n",
        "\n",
        "    def spectral_coherence(self):\n",
        "        \"\"\"Spectral Coherence\"\"\"\n",
        "        f, Cxy = scipy.signal.coherence(self.original, self.processed, fs=self.sr)\n",
        "        return np.mean(Cxy)\n",
        "\n",
        "    def harmonic_to_noise_ratio(self):\n",
        "        \"\"\"Harmonic-to-Noise Ratio (HNR)\"\"\"\n",
        "        return librosa.effects.harmonic(self.processed).mean() / librosa.effects.percussive(self.processed).mean()\n",
        "\n",
        "    def itakura_saito_distance(self):\n",
        "        \"\"\"Itakura-Saito Distance\"\"\"\n",
        "        orig_psd = np.abs(librosa.stft(self.original)) ** 2\n",
        "        proc_psd = np.abs(librosa.stft(self.processed)) ** 2\n",
        "        return np.mean(orig_psd / proc_psd - np.log(orig_psd / proc_psd) - 1)\n",
        "\n",
        "    def bark_spectral_distortion(self):\n",
        "        \"\"\"Bark Spectral Distortion (Approximated using Mel-frequency)\"\"\"\n",
        "        orig_mel = librosa.feature.melspectrogram(y=self.original, sr=self.sr)\n",
        "        proc_mel = librosa.feature.melspectrogram(y=self.processed, sr=self.sr)\n",
        "        return np.mean(np.abs(orig_mel - proc_mel))\n",
        "\n",
        "    def tonality_index(self):\n",
        "        \"\"\"Tonality Index (Ratio of Harmonic Energy to Total Energy)\"\"\"\n",
        "        orig_harmonic = librosa.effects.harmonic(self.original)\n",
        "        proc_harmonic = librosa.effects.harmonic(self.processed)\n",
        "        return np.abs(np.mean(orig_harmonic) - np.mean(proc_harmonic))\n",
        "\n",
        "    def psnr(self):\n",
        "        \"\"\"Peak Signal-to-Noise Ratio (PSNR)\"\"\"\n",
        "        mse_val = self.mse()\n",
        "        max_val = np.max(self.original) ** 2\n",
        "        return 10 * np.log10(max_val / (mse_val + 1e-10))\n",
        "\n",
        "    def mse(self):\n",
        "        \"\"\"Mean Squared Error (MSE)\"\"\"\n",
        "        return np.mean((self.original - self.processed) ** 2)\n",
        "\n",
        "    def euclidean_distance(self):\n",
        "        \"\"\"Euclidean Distance\"\"\"\n",
        "        return np.linalg.norm(self.original - self.processed)\n",
        "\n",
        "    def manhattan_distance(self):\n",
        "        \"\"\"Manhattan Distance\"\"\"\n",
        "        return np.sum(np.abs(self.original - self.processed))\n",
        "\n",
        "    def cosine_distance(self):\n",
        "        \"\"\"Cosine Distance\"\"\"\n",
        "        return scipy.spatial.distance.cosine(self.original, self.processed)\n",
        "\n",
        "    def chebyshev_distance(self):\n",
        "        \"\"\"Chebyshev Distance\"\"\"\n",
        "        return np.max(np.abs(self.original - self.processed))\n",
        "\n",
        "    def shannon_entropy(self, signal):\n",
        "        \"\"\"Shannon Entropy\"\"\"\n",
        "        prob_dist = np.histogram(signal, bins=256, density=True)[0]\n",
        "        prob_dist = prob_dist[prob_dist > 0]\n",
        "        return -np.sum(prob_dist * np.log2(prob_dist))\n",
        "\n",
        "    def kl_divergence(self):\n",
        "        \"\"\"Kullback-Leibler (KL) Divergence\"\"\"\n",
        "        orig_hist = np.histogram(self.original, bins=256, density=True)[0] + 1e-10\n",
        "        proc_hist = np.histogram(self.processed, bins=256, density=True)[0] + 1e-10\n",
        "        return scipy.stats.entropy(orig_hist, proc_hist)\n",
        "\n",
        "    def pesq(self):\n",
        "        \"\"\"Perceptual Evaluation of Speech Quality (PESQ)\"\"\"\n",
        "        # PESQ requires signals to be resampled to 16 kHz or 8 kHz\n",
        "        if self.sr not in [8000, 16000]:\n",
        "            raise ValueError(\"PESQ requires sampling rate of 8000 Hz or 16000 Hz.\")\n",
        "        return pesq.pesq(self.sr, self.original, self.processed, 'wb')  # 'wb' for wideband\n",
        "\n",
        "    def stoi(self):\n",
        "        \"\"\"Short-Time Objective Intelligibility (STOI)\"\"\"\n",
        "        return stoi(self.original, self.processed, self.sr, extended=False)\n",
        "\n",
        "    def compute_all_metrics(self):\n",
        "        \"\"\"Compute all metrics\"\"\"\n",
        "        return {\n",
        "            'LSD': self.log_spectral_distance(),\n",
        "            'MCD': self.mel_cepstral_distance(),\n",
        "            'SegSNR': self.segmental_snr(),\n",
        "            'SFM': self.spectral_flatness_measure(),\n",
        "            'Spectral Centroid Distance': self.spectral_centroid_distance(),\n",
        "            'Spectral Coherence': self.spectral_coherence(),\n",
        "            'HNR': self.harmonic_to_noise_ratio(),\n",
        "            'Itakura-Saito Distance': self.itakura_saito_distance(),\n",
        "            'Bark Spectral Distortion': self.bark_spectral_distortion(),\n",
        "            'Tonality Index': self.tonality_index(),\n",
        "            'PSNR': self.psnr(),\n",
        "            'MSE': self.mse(),\n",
        "            'Euclidean': self.euclidean_distance(),\n",
        "            'Manhattan': self.manhattan_distance(),\n",
        "            'Cosine': self.cosine_distance(),\n",
        "            'Chebyshev': self.chebyshev_distance(),\n",
        "            'Shannon Entropy': self.shannon_entropy(self.processed),\n",
        "            'KL Divergence': self.kl_divergence(),\n",
        "            'PESQ': self.pesq(),\n",
        "            'STOI': self.stoi()\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "dchaYTOVy5bQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import librosa\n",
        "import zipfile\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ✅ Download function for datasets\n",
        "def download_dataset(url, save_path):\n",
        "    \"\"\"Download and extract a dataset if it doesn't already exist.\"\"\"\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "\n",
        "    zip_path = os.path.join(save_path, \"dataset.zip\")\n",
        "\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"Downloading dataset from {url} ...\")\n",
        "        response = requests.get(url, stream=True)\n",
        "        with open(zip_path, \"wb\") as file:\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                if chunk:\n",
        "                    file.write(chunk)\n",
        "\n",
        "    # Extract ZIP file\n",
        "    print(f\"Extracting dataset in {save_path} ...\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(save_path)\n",
        "\n",
        "    os.remove(zip_path)  # Remove zip file after extraction\n",
        "    print(\"Dataset downloaded and extracted.\")\n",
        "\n",
        "# ✅ Function to add White Gaussian Noise\n",
        "def add_white_gaussian_noise(signal, snr_db):\n",
        "    \"\"\"Add white Gaussian noise to a signal at a given SNR level.\"\"\"\n",
        "    signal_power = np.mean(signal ** 2)\n",
        "    noise_power = signal_power / (10 ** (snr_db / 10))\n",
        "    noise = np.sqrt(noise_power) * np.random.randn(len(signal))\n",
        "    return signal + noise\n",
        "\n",
        "# ✅ Function to process dataset\n",
        "def process_dataset(audio_files, sr=16000, snr_levels=[30, 20, 10, 5]):\n",
        "    \"\"\"Process all files in the dataset and compute metrics.\"\"\"\n",
        "\n",
        "    # Initialize results storage\n",
        "    results = {\n",
        "        snr: {metric: [] for metric in SignalMetrics(np.zeros(1), np.zeros(1)).compute_all_metrics().keys()}\n",
        "        for snr in snr_levels\n",
        "    }\n",
        "\n",
        "    for file in tqdm(audio_files, desc=\"Processing Audio Files\"):\n",
        "        try:\n",
        "            # Load the audio file\n",
        "            original, _ = librosa.load(file, sr=sr, duration=5.0)\n",
        "\n",
        "            # Check if the loaded file is long enough\n",
        "            if len(original) < 2048:\n",
        "                print(f\"Skipping {file}: Too short! (Length: {len(original)} samples)\")\n",
        "                continue  # Skip this file\n",
        "\n",
        "            # Process each SNR level\n",
        "            for snr in snr_levels:\n",
        "                noisy_signal = add_white_gaussian_noise(original, snr)\n",
        "                metrics = SignalMetrics(original, noisy_signal).compute_all_metrics()\n",
        "\n",
        "                # Store results\n",
        "                for metric in metrics:\n",
        "                    results[snr][metric].append(metrics[metric])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file}: {e}\")\n",
        "            continue  # Skip the problematic file\n",
        "\n",
        "    # Compute average results over all files\n",
        "    avg_results = {\n",
        "        snr: {metric: np.mean(results[snr][metric]) if results[snr][metric] else 0 for metric in results[snr]}\n",
        "        for snr in snr_levels\n",
        "    }\n",
        "    return avg_results\n",
        "\n",
        "# ✅ Step 1: Automate Dataset Download\n",
        "speech_dataset_url = \"https://zenodo.org/record/5036977/files/arabic_speech_commands.zip\"  # Example dataset (Change if needed)\n",
        "music_dataset_url = \"http://opihi.cs.uvic.ca/sound/genres.tar.gz\"  # GTZAN Music Dataset\n",
        "\n",
        "speech_dataset_path = \"./datasets/speech/\"\n",
        "music_dataset_path = \"./datasets/music/\"\n",
        "\n",
        "# Download & Extract\n",
        "download_dataset(speech_dataset_url, speech_dataset_path)\n",
        "download_dataset(music_dataset_url, music_dataset_path)\n",
        "\n",
        "# ✅ Step 2: Locate Audio Files\n",
        "speech_files = glob.glob(os.path.join(speech_dataset_path, \"**/*.wav\"), recursive=True)\n",
        "music_files = glob.glob(os.path.join(music_dataset_path, \"**/*.wav\"), recursive=True)\n",
        "\n",
        "# ✅ Step 3: Process Speech and Music Datasets\n",
        "if len(speech_files) == 0:\n",
        "    print(\"No speech files found! Check dataset path.\")\n",
        "else:\n",
        "    speech_results = process_dataset(speech_files)\n",
        "\n",
        "if len(music_files) == 0:\n",
        "    print(\"No music files found! Check dataset path.\")\n",
        "else:\n",
        "    music_results = process_dataset(music_files)\n",
        "\n",
        "# ✅ Step 4: Print Results\n",
        "print(\"Speech Results:\", speech_results)\n",
        "print(\"Music Results:\", music_results)\n"
      ],
      "metadata": {
        "id": "we054mmnbPDJ",
        "outputId": "58d9e093-8250-45d3-de3b-b7d7811ba7d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset from https://zenodo.org/record/5036977/files/arabic_speech_commands.zip ...\n",
            "Extracting dataset in ./datasets/speech/ ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "File is not a zip file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7052263f7198>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# Download & Extract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mdownload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_dataset_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeech_dataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0mdownload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusic_dataset_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmusic_dataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-7052263f7198>\u001b[0m in \u001b[0;36mdownload_dataset\u001b[0;34m(url, save_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Extract ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extracting dataset in {save_path} ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1378\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    }
  ]
}